[{"uri":"/01introduction.html","title":" what is text summary","tags":[],"description":"","content":"text summary（文档摘要） 随着互联网产生的文本数据越来越多，文本信息过载问题日益严重，对各类文本进行一个“降 维”处理显得非常必要，文本摘要便是其中一个重要的手段。 文本摘要旨在将文本或文本集合转换为包含关键信息的简短摘要。 文本摘要按照输入类型可分为单文档摘要和多文档摘要。单文档摘要从给定的一个文档中生成摘要，多文档摘要从给定的一组主题相关的文档中生成摘要。 按照输出类型可分为抽取式摘要和生成式摘要。抽取式摘要从源文档中抽取关键句和关键词组成摘要，摘要全部来源于原文。生成式摘要根据原文，允许生成新的词语、短语来组成摘要。 按照有无监督数据可以分为有监督摘要和无监督摘要。 本文主要关注单文档、有监督、抽取式、生成式摘要。\n"},{"uri":"/01introduction/100algorithm.html","title":"1.1 算法概述","tags":[],"description":"","content":"使用场景 根据生成方式可以分为生成式摘要和抽取式摘要。\n 抽取式摘要：找到一个文档中最重要的几个句子并对其进行拼接。 生成式摘要：是一个序列生成问题，通过源文档序列, 生成序列摘要序列  本workshop主要覆盖以下四个算法，对比结果如下 "},{"uri":"/01introduction/200data.html","title":"1.2 数据集","tags":[],"description":"","content":"1.公开数据集 (英文)  XSUM 227k BBC articles CNN/Dailymail，93k articles from the CNN, 220k articles from the Daily Mail NEWSROOM，1.3M article-summary pairs written by authors and editors in the newsrooms of 38 major publications Multi-News，56k pairs of news articles and their human-written summaries from the http://sitenewser.com Gigaword，4M examples extracted from news articles，the task is to generate theheadline from the first sentence arXiv, PubMed，two long documentdatasets of scientific publications from http://arXiv.org (113k) andPubMed (215k). The task is to generate the abstract fromthe paper body. BIGPATENT，1.3 millionU.S. patents along with human summaries under nine patent classification categories WikiHow在线http://WikiHow.com网站上的大量说明数据集。 200k示例中的每一个示例都包含多个指令步骤段落以及一个摘要句子。 任务是从段落中生成串联的摘要句。 Reddit TIFU，120K posts of informal stories from the online discussion forum Reddit AESLC 18k email bodies and their subjects from the Enron corpus BillSum 23k USCongressional bills and human-written reference summaries from the 103rd-115th (1993-2018) sessions of Congress.  2.公开数据集 (中文)  哈工大的新浪微博短文本摘要 LCSTS 教育新闻自动摘要语料chinese_abstractive_corpus NLPCC 2017 task3 Single Document Summarization 娱乐新闻等 “神策杯”2018高校算法大师赛 清华 THUCNews 总数量：830749个样本； 标题：平均字数 19，字数标准差 4，最大字数 48，最小数字 4； 正文：平均字数 892，字数标准差 1012，最大字数 78796，最小数字 31；  "},{"uri":"/02textrank.html","title":"基于Amazon SageMaker的TEXTRANK模型训练动手实验","tags":[],"description":"","content":"本章节中，将会部署一个带有gpu机型的Amazon SageMaker环境，然后使用TEXTRANK算法进行文档摘要。\nTEXTRANK介绍 将文本中的每个句子分别看做一个节点，如果两个句子有相似性，那么认为这两个句子对应的节点之间存在一条无向有权边。 公式中，Si,Sj分别表示两个句子词的个数总数，Wk表示句子中的词，那么分子部分的意思是同时出现在两个句子中的同一个词的个数，分母是对句子中词的个数求对数之和。分母这样设计可以遏制较长的句子在相似度计算上的优势。 我们可以根据以上相似度公式循环计算任意两个节点之间的相似度，根据阈值去掉两个节点之间相似度较低的边连接，构建出节点连接图，然后计算TextRank值，最后对所有TextRank值排序，选出TextRank值最高的几个节点对应的句子作为摘要。\nTextRank虽然考虑到了词之间的关系，但是仍然倾向于将频繁词作为关键词。\n"},{"uri":"/01introduction/300metrics.html","title":"1.3 评估指标","tags":[],"description":"","content":"文本生成目前的一大瓶颈是如何客观，准确的评价机器生成文本的质量。自动文档摘要评价方法大致分为两类：\n（1）内部评价方法：提供参考摘要，以参考摘要为基准评价系统摘要的质量。系统摘要与参考摘要越吻合，质量越高。\n（2）外部评价方法：不提供参考摘要，利用文档摘要代替原文档执行某个文档相关的应用。例如：文档检索、文档分类等，能够提高应用性能的摘要被认为是质量好的摘要。\n下面介绍两种比较简单的，经常用到的内部评价方法：\nEdmundson 适于抽取式文本摘要，比较机械文摘(自动文摘系统得到的文摘)与目标文摘(从原文中抽取的句子)的句子重合率的高低对系统摘要进行评价。\n计算公式：\n 重合率p = 匹配句子数/专家文摘句子数*100%  每一个机械文摘的重合率为按三个专家给出的文摘得到的重合率的平均值（其中，pi为相对于第i个专家的重合率，n为专家文摘总数）： ROUGE ROUGE（Recall-Oriented Understudy for Gisting Evaluation）基于摘要中n-gram的共现信息评价摘要，是一种面向n元词召回率的评价方法。 其中，Ref summaries表示标准摘要，count_match(n-gram)表示生成摘要和标准摘要中同时出现n-gram的个数，count(n-gram)表示参考摘要中出现的n-gram个数。\n"},{"uri":"/03bertseq2seq.html","title":"基于Amazon SageMaker的BERT-SEQ2SEQ模型训练动手实验","tags":[],"description":"","content":"模型架构 模型输入输出范例  输入：嘉实基金推出旗下第3只成长基金——嘉实领先成长股票型基金，目前该基金已获得证监会批复，将于近期正式发行。据悉，嘉实领先成长基金股票资产占基金资产的60%～95%，其中不低于80%的比例投资于领先成长企业。嘉实领先成长基金具有鲜明的“全市场成长风格”，其重点投资于中国经济中快速成长行业中的领先成长企业，力争获得双重超额收益。嘉实基金认为，伴随中国经济的深入调整，未来成长行业也将呈现鱼目混杂现象。需要通过在全市场范围中精选快速成长行业中成长战略清晰的领先成长企业，才有望获取丰厚的投资收益。据悉，嘉实领先成长基金将由嘉实策略增长的基金经理之一邵秋涛执掌 输出： 嘉 实 领 先 成 长 基 金 获 批  预训练介绍 基于bert的seq2seq是一个经典的生成式摘要方法，需要大量的预训练，适合于自动的段标题（短摘要生成）场景。本实验中，会附上训练的相关代码供参考，但不涉及模型训练部分，仅实验模型部署及使用。 本实验提供的预训练模型是基于中文数据集THUCNews，在ml.p3.16xlarge上进行训练3天得到。\nTHUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。我们在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。 每个新闻均为txt文件，第一句话为新闻摘要。\n"},{"uri":"/04pegusas.html","title":"基于Amazon SageMaker的PEGUSAS模型部署动手实验","tags":[],"description":"","content":"使用谷歌2020pegasus模型进行中文文档摘要\n谷歌于去年年底发布了一个精简型的机器语义分析项目：飞马(PEGASUS)：预先机器学习及训练后的自动文章摘要项目。近期这个项目迎来的新的版本，这个小型项目可以非常精准的自动提取出文章中的摘要，并且只用一千个训练模型就可以生成媲美人类的摘要内容。 利用提取的间隙句进行摘要概括的预训练模型（Pre-training with Extracted Gap-sentences for Abstractive Summarization）。就是设计一种间隙句生成的自监督预训练目标，来改进生成摘要的微调性能。\n本项目参考开源论坛对于中文版本的实现，以mT5为基础架构和初始权重，通过类似PEGASUS的方式进行预训练。\n"},{"uri":"/02textrank/0201overview.html","title":"环境准备","tags":[],"description":"","content":"Amazon SageMaker 环境准备\n要完成本workshop操作步骤，您需要准备一台Amazon SageMaker笔记本实例：\n实例类型： p3.xlarge 存储: 150G\n打开sagemaker，点击右上角的create notebook instance 填入如下配置信息，然后点击create notebook instance 然后可以看到，提示笔记本正在创建中 等待一会儿，创建完成，点击create notebook instance\n"},{"uri":"/02textrank/0210component.html","title":" texkrank模型实验","tags":[],"description":"","content":"TextRank算法可以用来从文本中提取关键词和摘要（重要的句子）。TextRank4ZH是针对中文文本的TextRank算法的python算法实现。\n原理 TextRank的详细原理请参考：\n Mihalcea R, Tarau P. TextRank: Bringing order into texts[C]. Association for Computational Linguistics, 2004.\n 关于TextRank4ZH的原理和使用介绍：使用TextRank算法为文本生成关键字和摘要\n关键词提取 将原文本拆分为句子，在每个句子中过滤掉停用词（可选），并只保留指定词性的单词（可选）。由此可以得到句子的集合和单词的集合。\n每个单词作为pagerank中的一个节点。设定窗口大小为k，假设一个句子依次由下面的单词组成：\nw1, w2, w3, w4, w5, ..., wn w1, w2, ..., wk、w2, w3, ...,wk+1、w3, w4, ...,wk+2等都是一个窗口。在一个窗口中的任两个单词对应的节点之间存在一个无向无权的边。\n基于上面构成图，可以计算出每个单词节点的重要性。最重要的若干单词可以作为关键词。\n关键短语提取 参照关键词提取提取出若干关键词。若原文本中存在若干个关键词相邻的情况，那么这些关键词可以构成一个关键词组。\n例如，在一篇介绍支持向量机的文章中，可以找到关键词支持、向量、机，通过关键词组提取，可以得到支持向量机。\n摘要生成 将每个句子看成图中的一个节点，若两个句子之间有相似性，认为对应的两个节点之间有一个无向有权边，权值是相似度。\n通过pagerank算法计算得到的重要性最高的若干句子可以当作摘要。\n示例 见example、test。\n使用说明 类TextRank4Keyword、TextRank4Sentence在处理一段文本时会将文本拆分成4种格式：\n sentences：由句子组成的列表。 words_no_filter：对sentences中每个句子分词而得到的两级列表。 words_no_stop_words：去掉words_no_filter中的停止词而得到的二维列表。 words_all_filters：保留words_no_stop_words中指定词性的单词而得到的二维列表。  本地部署 server\ngit clone https://github.com/jackie930/TextRank4ZH.git cd TextRank4ZH/apps/text_summry_endpoint sh build_and_push.sh docker run -v -d -p 8080:8080 textrank client\n# test  #curl http://localhost:8080/ping  # curl import requests import json url=\u0026#39;http://localhost:8080/invocations\u0026#39; data={\u0026#34;data\u0026#34;: \u0026#34;《半導體》Q1展望保守，世界垂淚2019/02/11 10:28時報資訊【時報記者沈培華台北報導】世界先進 (5347) 去年營運創歷史新高，每股純益達3.72元。但對今年首季展望保守，預計營收將比上季高點減近一成。世界先進於封關前股價拉高，今早則是開平走低。世界先進於年前台股封關後舉行法說會公布財報。公司去年營運表現亮麗，營收與獲利同創歷史新高紀錄。2018年全年營收289.28億元，年增16.1%，毛利率35.2%，拉升3.2個百分點，稅後淨利61.66億元，年增36.9%，營收與獲利同創歷史新高，每股純益3.72元。董事會通過去年度擬配發現金股利3.2元。展望第一季，受到客戶進入庫存調整，公司預期，本季營收估在67億至71億元，將季減8%至13%，毛利率將約34.5%至36.5%。此外，因應客戶需求，世界先進決定斥資2.36億美元，收購格芯新加坡8吋晶圓廠。世界先進於年前宣布，將購買格芯位於新加坡Tampines的8吋晶圓3E廠房、廠務設施、機器設備及微機電(MEMS)智財權與業務，交易總金額2.36億美元，交割日訂108年12月31日。格芯晶圓3E廠現有月產能3.5萬片8吋晶圓，世界先進每年將可增加超過40萬片8吋晶圓產能，增進公司明年起業績成長動能。TOP關閉\u0026#34;} data = json.dumps(data) r = requests.post(url,data=data) #show result print (r.text) 结果如下\n{\u0026#34;res\u0026#34;: {\u0026#34;关键词列表\u0026#34;: [\u0026#34;公司\u0026#34;, \u0026#34;後\u0026#34;, \u0026#34;於\u0026#34;, \u0026#34;客戶\u0026#34;, \u0026#34;世界\u0026#34;, \u0026#34;會\u0026#34;, \u0026#34;歷史\u0026#34;, \u0026#34;展望\u0026#34;, \u0026#34;高點\u0026#34;, \u0026#34;定斥\u0026#34;, \u0026#34;保守\u0026#34;, \u0026#34;去年\u0026#34;, \u0026#34;年度\u0026#34;, \u0026#34;金\u0026#34;, \u0026#34;廠務\u0026#34;, \u0026#34;智\u0026#34;, \u0026#34;時報\u0026#34;, \u0026#34;擬配\u0026#34;, \u0026#34;發現\u0026#34;, \u0026#34;公布\u0026#34;], \u0026#34;关键词权重\u0026#34;: [0.021830182644348436, 0.021326461850579626, 0.021079603384026722, 0.01895223347929955, 0.01805834763586865, 0.015857085161081398, 0.014919166963726964, 0.01471938511506705, 0.014620888893926702, 0.014620888893926702, 0.014001573075273081, 0.013746893722718052, 0.011987812728358822, 0.011987812728358822, 0.011643071195825557, 0.011643071195825555, 0.011533578138425806, 0.011474480918306437, 0.011474480918306437, 0.011389711378308801], \u0026#34;摘要列表\u0026#34;: [\u0026#34;《半導體》Q1展望保守，世界垂淚2019/02/11 10:28時報資訊【時報記者沈培華台北報導】世界先進 (5347) 去年營運創歷史新高，每股純益達3.72元\u0026#34;, \u0026#34;世界先進於年前宣布，將購買格芯位於新加坡Tampines的8吋晶圓3E廠房、廠務設施、機器設備及微機電(MEMS)智財權與業務，交易總金額2.36億美元，交割日訂108年12月31日\u0026#34;, \u0026#34;格芯晶圓3E廠現有月產能3.5萬片8吋晶圓，世界先進每年將可增加超過40萬片8吋晶圓產能，增進公司明年起業績成長動能\u0026#34;], \u0026#34;摘要位置index\u0026#34;: [0, 9, 10], \u0026#34;摘要权重\u0026#34;: [0.1061431564717524, 0.10339832449272994, 0.09211266281495177]}} Deploy endpoint on SageMaker #sin endpoint_ecr_image=\u0026#34;847380964353.dkr.ecr.ap-southeast-1.amazonaws.com/textrank\u0026#34; #ningxia #endpoint_ecr_image=\u0026#34;251885400447.dkr.ecr.cn-northwest-1.amazonaws.com.cn/textrank\u0026#34; python create_endpoint.py \\ --endpoint_ecr_image_path ${endpoint_ecr_image} \\ --endpoint_name \u0026#39;textrank\u0026#39; \\ --instance_type \u0026#34;ml.t2.medium\u0026#34; 在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\nfrom boto3.session import Session import json data={\u0026#34;data\u0026#34;: \u0026#34;《半導體》Q1展望保守，世界垂淚2019/02/11 10:28時報資訊【時報記者沈培華台北報導】世界先進 (5347) 去年營運創歷史新高，每股純益達3.72元。但對今年首季展望保守，預計營收將比上季高點減近一成。世界先進於封關前股價拉高，今早則是開平走低。世界先進於年前台股封關後舉行法說會公布財報。公司去年營運表現亮麗，營收與獲利同創歷史新高紀錄。2018年全年營收289.28億元，年增16.1%，毛利率35.2%，拉升3.2個百分點，稅後淨利61.66億元，年增36.9%，營收與獲利同創歷史新高，每股純益3.72元。董事會通過去年度擬配發現金股利3.2元。展望第一季，受到客戶進入庫存調整，公司預期，本季營收估在67億至71億元，將季減8%至13%，毛利率將約34.5%至36.5%。此外，因應客戶需求，世界先進決定斥資2.36億美元，收購格芯新加坡8吋晶圓廠。世界先進於年前宣布，將購買格芯位於新加坡Tampines的8吋晶圓3E廠房、廠務設施、機器設備及微機電(MEMS)智財權與業務，交易總金額2.36億美元，交割日訂108年12月31日。格芯晶圓3E廠現有月產能3.5萬片8吋晶圓，世界先進每年將可增加超過40萬片8吋晶圓產能，增進公司明年起業績成長動能。TOP關閉\u0026#34;} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;textrank\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 使用rouge指标评估 ###安装pyrouge\nsudo yum -y install perl-CPAN sudo cpan YAML sudo cpan Module::Metadata sudo cpan Module::Build sudo cpan IO::Socket sudo cpan IO::Socket::IP sudo cpan HTTP::Daemon sudo cpan LWP::UserAgent sudo cpan DB_File cd pyrouge cd tools/ROUGE-1.5.5/data/ rm WordNet-2.0.exc.db ./WordNet-2.0-Exceptions/buildExeptionDB.pl ./WordNet-2.0-Exceptions ./smart_common_words.txt ./WordNet-2.0.exc.db pyrouge_set_rouge_path /home/ec2-user/SageMaker/pyrouge/tools/ROUGE-1.5.5 cd ../../../ pyrouge_set_rouge_path /home/ec2-user/SageMaker/pyrouge/tools/ROUGE-1.5.5 python setup.py install** 测试评估 python test_rouge.py 结果产生为如下格式的结果表\n   原文 标注摘要 生成摘要 评估指标rouge1 评估指标rouge2     text text text number number    "},{"uri":"/04pegusas/0401prepare.html","title":"pegasus模型实验","tags":[],"description":"","content":"##预训练任务\n预训练任务模仿了PEGASUS的摘要式预训练。具体来说，假设一个文档有n个句子，我们从中挑出大约n/4个句子（可以不连续），使得这n/4个句子拼起来的文本，跟剩下的3n/4个句子拼起来的文本，最长公共子序列尽可能长，然后我们将3n/4个句子拼起来的文本视为原文，n/4个句子拼起来的文本视为摘要，通过这样的方式构成一个“(原文, 摘要)”的伪摘要数据对。\n运行环境：tensorflow 1.15 + keras 2.3.1 + bert4keras 0.10.0\n模型下载 quick start train 将待训练的数据集放在data目录下\ngit clone https://github.com/jackie930/t5-pegasus-textsummary.git source activate tensorflow_p36 pip install tensorflow==1.15 keras==2.3.1 bert4keras==0.10.0 jieba tqdm rouge python finetune.py 训练结束会产生一个keras结构的模型文件 - best_model.weights\n预测 下载模型文件，目录结构为\nchinese_t5_pegasus_base/ best_model.weights\npython test.py 评估 运行 python evaluatiion.py\n得到结果 {'rouge-1': 0.885041123153444, 'rouge-2': 0.8795828353099052, 'rouge-l': 0.9046418758557804, 'bleu': 0.8239310846742561}\n部署 #make sure you got trained models sh build_and_push.sh run on endpoint\n#sin endpoint_ecr_image=\u0026#34;847380964353.dkr.ecr.ap-southeast-1.amazonaws.com/pegasus\u0026#34; #ningxia #endpoint_ecr_image=\u0026#34;251885400447.dkr.ecr.cn-northwest-1.amazonaws.com.cn/pegasus\u0026#34; python create_endpoint.py \\ --endpoint_ecr_image_path ${endpoint_ecr_image} \\ --endpoint_name \u0026#39;pegasus\u0026#39; \\ --instance_type \u0026#34;ml.g4dn.2xlarge\u0026#34; 在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\nfrom boto3.session import Session import json txt = \u0026#34;来源|零壹财经作者|任俊东12月1日，国家互联网信息办公室发布关于《常见类型移动互联网应用程序（App）必要个人信息范围》公开征求意见的通知。此次《意见稿》规定了支付、借贷、银行等38类常见类型App必要个人信息范围，明确App必要个人信息界限，不得因非必要信息拒绝用户安装使用。零壹财经自今年3月起开展了手机App评测工作，通过对金融、购物、视频等10大类300多款App评测发现，9成以上APP都存在违规收集信息问题，其中违反必要原则，收集与其业务无关的个人信息、用户拒绝同意就无法安装使用等问题最为严重。上月，全国App个人信息保护监管会召开。会上阿里、腾讯、字节等互联网巨头遭监管点名批评：在App个人信息保护工作方面，存在思想漠视、侥幸心理、技术对抗三类问题。1.对38类App必要个人信息范围向社会征求意见针对此次《意见稿》，国家网信办表示，近年来App广泛应用在促进经济社会发展、服务民生等方面发挥了重要作用。同时，App超范围收集、强制收集用户个人信息普遍存在，用户拒绝同意就无法安装使用。为落实《中华人民共和国网络安全法》关于个人信息收集合法、正当、必要的原则，规范App个人信息收集行为，因而明确常见App收集必要个人信息范围。意见反馈时间截止到2020年12月16日。2.12类App无须个人信息，即可使用基本功能服务根据《意见稿》，国家网信办拟规定网络直播、在线影音、短视频、新闻资讯、运动健身、浏览器、输入法、安全管理、电子图书、拍摄美化、应用商店、实用工具类共12类App无须个人信息，即可使用基本功能服务。3.零壹App评测：9成以上App存在违规收集信息问题为规范收集APP信息收集和使用、加强个人信息保护，切实维护收集APP消费者合法权益，并依据相关监管政策法规，零壹财经App评测中心于2020年3月2日启动App评测专项工作。中心相关评测工作得到了App消费者、监管部门、相关企业、行业从业者等多方的广泛关注和支持。通过对金融、购物、视频等10大类300多款App评测发现，9成以上APP都存在违规收集信息问题，其中违反必要原则，收集与其业务无关的个人信息、用户拒绝同意就无法安装使用等问题最为严重。4.阿里、腾讯、字节等遭监管点名批评，App个人信息保护进入新的发展阶段11月27日，全国App个人信息保护监管会在北京召开，工信部召集国内互联网行业的头部企业，总结过去半年来App个人信息保护专项整治行动的成果，部署下一阶段整治行动。工信部信息通信管理局副局长鲁春从在会上表示，工信部针对大企业的App进行了全覆盖检测，对阿里巴巴的40余款、字节跳动30余款，腾讯30余款、百度20余款、网易10余款、小米10余款用户下载量大、使用率高的App进行了重点检测，发现存在思想漠视、侥幸心理、技术对抗三类问题。互联网个人信息数据野蛮生长时代已成过去，APP个人信息保护正在迎来新的发展阶段。切实维护用户合法权益，严厉惩处互联网企业违法违规行为是今后互联网监管的常态。企业只有从思想上重视、行动上遵守，把用户的利益作为企业的核心关切，才能持续发展。添加作者微信：daodao0312，可获取《常见类型移动互联网应用程序（App）必要个人信息范围（征求意见稿）》，或您有App评测需求请联系作者。\u0026#34; data={\u0026#34;data\u0026#34;: txt} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;pegasus\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) "},{"uri":"/03bertseq2seq/0301train.html","title":" bert-seq2seq模型实验","tags":[],"description":"","content":"首先下载代码\ncd SageMaker git clone https://github.com/jackie930/bert-seq2seq-textsummary.git 然后部署一个预置的endpoint\n#sin endpoint_ecr_image=\u0026#34;847380964353.dkr.ecr.ap-southeast-1.amazonaws.com/bertseq2seq\u0026#34; #ningxia #endpoint_ecr_image=\u0026#34;251885400447.dkr.ecr.cn-northwest-1.amazonaws.com.cn/bertseq2seq\u0026#34; python create_endpoint.py \\ --endpoint_ecr_image_path ${endpoint_ecr_image} \\ --endpoint_name \u0026#39;bertseq2seq\u0026#39; \\ --instance_type \u0026#34;ml.p2.xlarge\u0026#34; 在部署结束后，看到SageMaker控制台生成了对应的endpoint,可以使用如下客户端代码测试调用\nfrom boto3.session import Session import json txt = \u0026#34;嘉实基金推出旗下第3只成长基金——嘉实领先成长股票型基金，目前该基金已获得证监会批复，将于近期正式发行。据悉，嘉实领先成长基金股票资产占基金资产的60%～95%，其中不低于80%的比例投资于领先成长企业。嘉实领先成长基金具有鲜明的“全市场成长风格”，其重点投资于中国经济中快速成长行业中的领先成长企业，力争获得双重超额收益。嘉实基金认为，伴随中国经济的深入调整，未来成长行业也将呈现鱼目混杂现象。需要通过在全市场范围中精选快速成长行业中成长战略清晰的领先成长企业，才有望获取丰厚的投资收益。据悉，嘉实领先成长基金将由嘉实策略增长的基金经理之一邵秋涛执掌\u0026#34; data={\u0026#34;data\u0026#34;: txt} session = Session() runtime = session.client(\u0026#34;runtime.sagemaker\u0026#34;) response = runtime.invoke_endpoint( EndpointName=\u0026#39;bertseq2seq\u0026#39;, ContentType=\u0026#34;application/json\u0026#34;, Body=json.dumps(data), ) result = json.loads(response[\u0026#34;Body\u0026#34;].read()) print (result) 结果如下\n{'摘要': '嘉 实 领 先 成 长 基 金 获 证 监 会 批 复'} CPU times: user 72.6 ms, sys: 20.7 ms, total: 93.3 ms Wall time: 807 ms 训练部分可以参考github中readme部分。\n"},{"uri":"/","title":"AWS Datalab- 文档摘要","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Applied Scientist)  概述 本次workshop分为几个部分\n 背景介绍- what is text summary？ 基于Amazon SageMaker的TEXTRANK模型训练动手实验 基于Amazon SageMaker的BERT-SEQ2SEQ模型训练动手实验 基于Amazon SageMaker的PEGUSAS模型部署动手实验  本次 workshop 前提 本次 workshop 建议在 宁夏 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以宁夏 Region 为例。\n"},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]